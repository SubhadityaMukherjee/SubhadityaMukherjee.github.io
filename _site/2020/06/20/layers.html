<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">

</script>
    <!-- To automatically render math in text elements, include the auto-render extension: --> 

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Linear Model | Deconstructing Deep learning</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Linear Model" />
<meta name="author" content="Subhaditya Mukherjee" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Let us start the fun with a simple model which will be extended to fit complex needs." />
<meta property="og:description" content="Let us start the fun with a simple model which will be extended to fit complex needs." />
<link rel="canonical" href="http://localhost:4000/2020/06/20/layers.html" />
<meta property="og:url" content="http://localhost:4000/2020/06/20/layers.html" />
<meta property="og:site_name" content="Deconstructing Deep learning" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-20T12:43:30+04:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"http://localhost:4000/2020/06/20/layers.html","headline":"Linear Model","dateModified":"2020-06-20T12:43:30+04:00","datePublished":"2020-06-20T12:43:30+04:00","author":{"@type":"Person","name":"Subhaditya Mukherjee"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2020/06/20/layers.html"},"description":"Let us start the fun with a simple model which will be extended to fit complex needs.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h2><a id = "imp" href="http://localhost:4000/">Home page</a></h2>
        
        
        
        
        <p>Making a Deep Learning library from scratch and explaining it the whole way + δeviations</p>
        
        <p>
          Drop me an <a href = "mailto: msubhaditya@gmail.com">email</a>
          | RSS feed link : <a href ="https://subhadityamukherjee.github.io/feed.xml">Click</a> | Source? Refer to<a href="https://github.com/SubhadityaMukherjee/DataLoader.jl"> the repository</a><br>
          The posts are in the order of newer -> older <br>
          Format : 
          Date | Title<br>
          &emsp;&emsp;TL; DR<br>
          &#9998;: Post, &#9883; : Deviation, &#128214;: Book notes
          <div id="search-container">
            Search for something in the blog <input type="text" id="search-input" placeholder="search...">
            
          </div>
          <ul id="results-container"></ul>
        </p>
        
        
        <p class="view"><a href="">View My GitHub Profile</a></p>
      </header>
      
      <hr>
      <!-- Html Elements for Search -->
      
      <!-- Script pointing to search-script.js -->
      <script src="js/search-script.js" type="text/javascript"></script>
      
      <!-- Configuration -->
      <script>
        SimpleJekyllSearch({
          searchInput: document.getElementById('search-input'),
          resultsContainer: document.getElementById('results-container'),
          json: '/search.json'
        })
        </script>
<section>
  <a href = "/deconstructingdl.html">Go to index</a><br><br>


<small>20 June 2020</small>
<h1>Linear Model</h1>

<span class="reading-time" title="Estimated read time">
  
  
    <h3>Reading time : ~4 mins</h3>
  
</span>


<p class="view">by Subhaditya Mukherjee</p>


<p>Let us start the fun with a simple model which will be extended to fit complex needs.</p>

<p>The first and easiest model we can think of to start with is the Dense or fully connected Linear layer model. Once we have this working, this can be extended further. So what is this layer? Simply put, W*x.+b where W and b are the initialized weights and biases. For now these are random. Later we will check out Kaiming/glorot initialization instead.</p>

<p>Let us make W and b first. And let us also take a random x, y array so we can perform the task at hand.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">5</span><span class="x">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="mi">2</span><span class="x">)</span>
<span class="n">x</span><span class="x">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="mi">5</span><span class="x">),</span><span class="n">rand</span><span class="x">(</span><span class="mi">2</span><span class="x">)</span>
</code></pre></div></div>

<p>Okay now that we have this. We need to find the gradients aka backprop. In Julia, we use a library called Zygote. Basically this is a differential programming library which will allow us to calculate the gradients on the fly and pretty easily. To do this we use.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gs</span> <span class="o">=</span> <span class="n">gradient</span><span class="x">(()</span> <span class="o">-&gt;</span> <span class="n">loss</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">),</span> <span class="n">Params</span><span class="x">([</span><span class="n">W</span><span class="x">,</span> <span class="n">b</span><span class="x">]))</span>
</code></pre></div></div>
<p>Once we have this, we can use it to find the updated weights. We can now apply our linear layer that we defined earlier. We take the previous weight and update it as α.*W̄ where α is the learning rate. An extremely important parameter which we will keep coming back to as we go along.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W̄</span> <span class="o">=</span> <span class="n">gs</span><span class="x">[</span><span class="n">W</span><span class="x">]</span>
<span class="n">W</span><span class="o">.=</span> <span class="n">α</span><span class="o">.*</span><span class="n">W̄</span>
<span class="n">ŷ</span> <span class="o">=</span>  <span class="n">W</span><span class="o">*</span><span class="n">x</span><span class="o">.+</span><span class="n">b</span>
</code></pre></div></div>

<p>Okay now on to finding exactly how good our model did. To do this we define a simple loss function. Here we will use Mean Squared error. It is the simplest metric and all it does is find the square of the mean of the differences between the predicted and original. This is also simple to define.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sum</span><span class="x">((</span><span class="n">y</span><span class="o">-</span><span class="n">ŷ</span><span class="x">)</span><span class="o">.^</span><span class="mi">2</span><span class="x">)</span>
</code></pre></div></div>

<p>So now we have a proper loop! Which actually runs and gives us a minimized loss!
We run this bit as many times as needed to get results.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">a</span> <span class="k">in</span> <span class="n">collect</span><span class="x">(</span><span class="mi">1</span><span class="o">:</span><span class="mi">100</span><span class="x">)</span>
    <span class="n">gs</span> <span class="o">=</span> <span class="n">gradient</span><span class="x">(()</span> <span class="o">-&gt;</span> <span class="n">loss</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">),</span> <span class="n">Params</span><span class="x">([</span><span class="n">W</span><span class="x">,</span> <span class="n">b</span><span class="x">]))</span>
    <span class="n">W̄</span> <span class="o">=</span> <span class="n">gs</span><span class="x">[</span><span class="n">W</span><span class="x">]</span>
    <span class="n">W</span><span class="o">.=</span> <span class="n">α</span><span class="o">.*</span><span class="n">W̄</span>
    <span class="n">ŷ</span> <span class="o">=</span>  <span class="n">W</span><span class="o">*</span><span class="n">x</span><span class="o">.+</span><span class="n">b</span>
    <span class="nd">@info</span> <span class="n">sum</span><span class="x">((</span><span class="n">y</span><span class="o">-</span><span class="n">ŷ</span><span class="x">)</span><span class="o">.^</span><span class="mi">2</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>


<section>
<!-- <ul> -->
Related posts:&emsp;

<!-- <li> -->
  <a href=/2020/07/04/padding.html> Padding&emsp; </a>
  <!-- </li> -->

<!-- <li> -->
  <a href=/2020/07/03/fasterConv.html> Faster and more general Conv&emsp; </a>
  <!-- </li> -->

<!-- <li> -->
  <a href=/2020/07/02/kernels.html> Image kernels&emsp; </a>
  <!-- </li> -->

<!-- <li> -->
  <a href=/2020/07/02/convolution.html> Basic Convolution&emsp; </a>
  <!-- </li> -->

<!-- <li> -->
  <a href=/article/2020/07/01/time.html> Imposter Syndrome in the research community&emsp; </a>
  <!-- </li> -->

<!-- <li> -->
  <a href=/2020/06/30/latex-from-code.html> latex from code&emsp; </a>
  <!-- </li> -->

<!-- <li> -->
  <a href=/2020/06/30/loss-functions.html> Loss Functions&emsp; </a>
  <!-- </li> -->

<!-- <li> -->
  <a href=/2020/06/27/Implementing-Papers.html> Implementing Papers&emsp; </a>
  <!-- </li> -->

<!-- <li> -->
  <a href=/book/2020/06/27/100PageMlbook.html> 100PageMlblook&emsp; </a>
  <!-- </li> -->

<!-- <li> -->
  <a href=/2020/06/24/SGD.html> SGD&emsp; </a>
  <!-- </li> -->


</section>
<!-- </ul> -->




      <footer>
        
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
  </body>
</html>