<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">

</script>

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Activation functions | Deconstructing Deep learning</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Activation functions" />
<meta name="author" content="Subhaditya Mukherjee" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Implementing activation functions." />
<meta property="og:description" content="Implementing activation functions." />
<meta property="og:site_name" content="Deconstructing Deep learning" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-19T22:00:43+00:00" />
<script type="application/ld+json">
{"description":"Implementing activation functions.","url":"/article/2020/06/19/activationFunctions.html","@type":"BlogPosting","headline":"Activation functions","dateModified":"2020-06-19T22:00:43+00:00","datePublished":"2020-06-19T22:00:43+00:00","author":{"@type":"Person","name":"Subhaditya Mukherjee"},"mainEntityOfPage":{"@type":"WebPage","@id":"/article/2020/06/19/activationFunctions.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/landing.css?v=">
  </head>
  <body>
    <div class="col-md-4">
      <header>
        <h2><a id = "imp" href="/">Home page</a></h2>
        <p>Deconstructing Deep Learning +  δeviations</p>
        
        <p>
          Drop me an <a href = "mailto: msubhaditya@gmail.com">email</a>
          | RSS feed link : <a href ="https://subhadityamukherjee.github.io/feed.xml">Click</a> <br>
          Format : 
          Date | Title<br>
          &emsp;&emsp;TL; DR<br>
          <h4>Total number of posts : 88</h4>
         Go To : <a style="font-size:20px;color:white;" href="#PAPER">PAPERS</a> o
        <a style="font-size:20px;color:white;" href="#ARTICLE">ARTICLES</a> o
        <a style="font-size:20px;color:white;" href="#BOOK">BOOKS</a> o
        <a style="font-size:20px;color:white;" href="#SPACE">SPACE</a>
         
        </p>
        
        <p class="view">
        <a href="https://www.github.com/SubhadityaMukherjee">View My GitHub Profile </a>
        </p>
      </header>
      
      <hr>
    </div>
<section>
      <div class="col-md-5">
  <a href = "/deeplearning.html">Go to index</a><br><br>


<h1>Activation functions</h1>

<span class="reading-time" title="Estimated read time">
  
  
    <h3>Reading time : ~4 mins</h3>
  
</span>


<p class="view">by Subhaditya Mukherjee</p>
<ul>
  <li><a href="#relu">Relu</a></li>
  <li><a href="#leaky-relu">Leaky relu</a></li>
  <li><a href="#prelu">PRelu</a></li>
  <li><a href="#maxout">Maxout</a></li>
  <li><a href="#sigmoid">Sigmoid</a></li>
  <li><a href="#noisy-relu">Noisy Relu</a></li>
  <li><a href="#softplus">Softplus</a></li>
  <li><a href="#elu">Elu</a></li>
  <li><a href="#swish">Swish</a></li>
</ul>

<p>Implementing activation functions.</p>

<p>Activation functions are an extremely important part of any neural network. But they are actually much simpler than we make them out to be. Here are some of them.
Lets define a test matrix.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test</span> <span class="o">=</span> <span class="x">[</span><span class="mi">100</span> <span class="mf">1.0</span> <span class="mf">0.0</span> <span class="o">-</span><span class="mf">300.0</span><span class="x">;</span><span class="mi">100</span> <span class="mf">1.0</span> <span class="mf">0.0</span> <span class="mf">300.0</span><span class="x">]</span>
</code></pre></div></div>

<h2 id="relu">Relu</h2>
<ul>
  <li>The Rectified Linear Unit (ReLU) activation function produces 0 as an output when x &lt; 0, and then produces a linear with slope of 1 when x &gt; 0.</li>
  <li>Nair, V., &amp; Hinton, G. E. (2010, January). Rectified linear units improve restricted boltzmann machines. In ICML.</li>
  <li>f(x) = max(0,x)</li>
</ul>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">relu</span><span class="x">(</span><span class="n">mat</span><span class="x">)</span> <span class="o">=</span> <span class="n">max</span><span class="o">.</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">mat</span><span class="x">)</span>
</code></pre></div></div>

<h2 id="leaky-relu">Leaky relu</h2>
<ul>
  <li>Andrew L. Maas, Awni Y. Hannun, Andrew Y. Ng (2014). Rectifier Nonlinearities Improve Neural Network Acoustic Models.</li>
  <li>f(x) = max(0.01x,x)</li>
</ul>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lrelu</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="n">max</span><span class="o">.</span><span class="x">(</span><span class="mf">0.01</span><span class="n">x</span><span class="x">,</span> <span class="n">x</span><span class="x">)</span>
</code></pre></div></div>

<h2 id="prelu">PRelu</h2>
<ul>
  <li>f(x) = max(x, x*a)</li>
</ul>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#export</span>
<span class="n">prelu</span><span class="x">(</span><span class="n">x</span><span class="x">,</span><span class="n">a</span><span class="x">)</span> <span class="o">=</span> <span class="n">max</span><span class="o">.</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">x</span><span class="o">.*</span><span class="n">a</span><span class="x">)</span>
<span class="n">prelu</span><span class="x">(</span><span class="n">test</span><span class="x">,</span><span class="mf">0.10</span><span class="x">)</span>
</code></pre></div></div>

<h2 id="maxout">Maxout</h2>
<ul>
  <li>f(x) = max(x, x*a)</li>
</ul>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">maxout</span><span class="x">(</span><span class="n">x</span><span class="x">,</span><span class="n">a</span><span class="x">)</span> <span class="o">=</span> <span class="n">max</span><span class="o">.</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">x</span><span class="o">.*</span><span class="n">a</span><span class="x">)</span>
<span class="n">maxout</span><span class="x">(</span><span class="n">test</span><span class="x">,</span><span class="mf">0.10</span><span class="x">)</span>
</code></pre></div></div>

<h2 id="sigmoid">Sigmoid</h2>
<ul>
  <li>f(x) = 1/(1+e^-x)</li>
</ul>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">σ</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">./</span><span class="x">(</span><span class="mi">1</span> <span class="o">.+</span><span class="n">exp</span><span class="o">.</span><span class="x">(</span><span class="o">-</span><span class="n">x</span><span class="x">))</span>
<span class="n">σ</span><span class="x">(</span><span class="n">test</span><span class="x">)</span>
</code></pre></div></div>

<h2 id="noisy-relu">Noisy Relu</h2>
<ul>
  <li>f(x) = max(0, x+Y) where YϵNormal(0,1)</li>
</ul>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">Distributions</span>
<span class="n">noisyrelu</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="n">max</span><span class="o">.</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">x</span><span class="o">.+</span><span class="n">rand</span><span class="x">(</span><span class="n">Distributions</span><span class="o">.</span><span class="n">Normal</span><span class="x">(),</span> <span class="mi">1</span><span class="x">))</span>
<span class="n">noisyrelu</span><span class="x">(</span><span class="n">test</span><span class="x">)</span>
</code></pre></div></div>

<h2 id="softplus">Softplus</h2>
<ul>
  <li>f(x) = log(e^x+1)</li>
</ul>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">softplus</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="n">log</span><span class="o">.</span><span class="x">(</span><span class="n">exp</span><span class="o">.</span><span class="x">(</span><span class="n">test</span><span class="x">)</span><span class="o">.+</span><span class="mi">1</span><span class="x">)</span>
<span class="n">softplus</span><span class="x">(</span><span class="n">test</span><span class="x">)</span>
</code></pre></div></div>

<h2 id="elu">Elu</h2>
<ul>
  <li>f(x) = max(x, a*(e^x-1))</li>
</ul>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">elu</span><span class="x">(</span><span class="n">x</span><span class="x">,</span><span class="n">a</span><span class="x">)</span> <span class="o">=</span> <span class="n">max</span><span class="o">.</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">a</span><span class="o">.*</span><span class="x">(</span><span class="n">exp</span><span class="o">.</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">.-</span><span class="mi">1</span><span class="x">))</span>
<span class="n">elu</span><span class="x">(</span><span class="n">test</span><span class="x">,</span><span class="mf">0.1</span><span class="x">)</span>
</code></pre></div></div>

<h2 id="swish">Swish</h2>
<ul>
  <li>f(x) = x/(1+e^(-βx))</li>
</ul>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">swish</span><span class="x">(</span><span class="n">x</span><span class="x">,</span><span class="n">β</span><span class="x">)</span> <span class="o">=</span> <span class="n">x</span> <span class="o">./</span><span class="x">(</span><span class="mi">1</span> <span class="o">.+</span><span class="n">exp</span><span class="o">.</span><span class="x">(</span><span class="o">-</span><span class="n">β</span><span class="o">.*</span><span class="n">x</span><span class="x">))</span>
<span class="n">swish</span><span class="x">(</span><span class="n">test</span><span class="x">,</span><span class="mf">0.1</span><span class="x">)</span>
</code></pre></div></div>


<section>
Related posts:&emsp;

  <a href=/book/2021/03/09/AISuperpowersKaiFuLee.html> AI Superpowers Kai Fu Lee&emsp; </a>

  <a href=/book/2021/03/07/DigitalMinimalismCalNewport.html> Digital Minimalism Cal Newport&emsp; </a>

  <a href=/article/2021/03/05/tricksFromLectures.html> More Deep Learning, Less Crying - A guide&emsp; </a>

  <a href=/article/2020/10/09/SuperRes.html> Super resolution&emsp; </a>

  <a href=/article/2020/10/07/FederatedLearning.html> Federated Learning&emsp; </a>

  <a href=/article/2020/10/03/TakingBatchnormForGranted.html> Taking Batchnorm For Granted&emsp; </a>

  <a href=/article/2020/09/28/AdversarialAttack.html> A murder mystery and Adversarial attack&emsp; </a>

  <a href=/article/2020/09/26/An.html> Thank you and a rain check&emsp; </a>

  <a href=/article/2020/09/25/Pruning.html> Pruning&emsp; </a>

  <a href=/article/2020/09/04/Documentation.html> Documentation using Documenter.jl&emsp; </a>


</section>


    </div>
  </body>
</html>
