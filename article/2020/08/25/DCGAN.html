<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">

</script>

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>DCGAN | Deconstructing Deep learning</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="DCGAN" />
<meta name="author" content="Subhaditya Mukherjee" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Here we will talk about Generative Networks and implement a simple version of DC GAN." />
<meta property="og:description" content="Here we will talk about Generative Networks and implement a simple version of DC GAN." />
<meta property="og:site_name" content="Deconstructing Deep learning" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-08-25T20:03:00+00:00" />
<script type="application/ld+json">
{"description":"Here we will talk about Generative Networks and implement a simple version of DC GAN.","url":"/article/2020/08/25/DCGAN.html","@type":"BlogPosting","headline":"DCGAN","dateModified":"2020-08-25T20:03:00+00:00","datePublished":"2020-08-25T20:03:00+00:00","author":{"@type":"Person","name":"Subhaditya Mukherjee"},"mainEntityOfPage":{"@type":"WebPage","@id":"/article/2020/08/25/DCGAN.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/landing.css?v=">
  </head>
  <body>
    <div class="col-md-4">
      <header>
        <h2><a id = "imp" href="/">Home page</a></h2>
        <p>Deconstructing Deep Learning +  δeviations</p>
        
        <p>
          Drop me an <a href = "mailto: msubhaditya@gmail.com">email</a>
          | RSS feed link : <a href ="https://subhadityamukherjee.github.io/feed.xml">Click</a> <br>
          Format : 
          Date | Title<br>
          &emsp;&emsp;TL; DR<br>
          <h4>Total number of posts : 88</h4>
         Go To : <a style="font-size:20px;color:white;" href="#PAPER">PAPERS</a> o
        <a style="font-size:20px;color:white;" href="#ARTICLE">ARTICLES</a> o
        <a style="font-size:20px;color:white;" href="#BOOK">BOOKS</a> o
        <a style="font-size:20px;color:white;" href="#SPACE">SPACE</a>
         
        </p>
        
        <p class="view">
        <a href="https://www.github.com/SubhadityaMukherjee">View My GitHub Profile </a>
        </p>
      </header>
      
      <hr>
    </div>
<section>
      <div class="col-md-5">
  <a href = "/deeplearning.html">Go to index</a><br><br>


<h1>DCGAN</h1>

<span class="reading-time" title="Estimated read time">
  
  
    <h3>Reading time : ~22 mins</h3>
  
</span>


<p class="view">by Subhaditya Mukherjee</p>
<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#examples">Examples</a></li>
  <li><a href="#code">Code</a>
    <ul>
      <li><a href="#imports">Imports</a></li>
      <li><a href="#constants">Constants</a></li>
      <li><a href="#discriminator">Discriminator</a></li>
      <li><a href="#generator">Generator</a></li>
      <li><a href="#conv-transpose">Conv Transpose</a></li>
      <li><a href="#loss-functions">Loss functions.</a></li>
      <li><a href="#training">Training</a></li>
      <li><a href="#data">Data</a></li>
      <li><a href="#loop">Loop</a></li>
      <li><a href="#output-image">Output image</a></li>
    </ul>
  </li>
  <li><a href="#further-reading">Further reading</a></li>
</ul>

<p>Here we will talk about Generative Networks and implement a simple version of DC GAN.</p>

<h1 id="introduction">Introduction</h1>
<p>GAN? -&gt; Generative Adversarial Network. This came about as an attempt to have a neural network create something new from images instead of just using them to perform supervised tasks.</p>

<p>Why? -&gt; Many reasons. Art being one of them. The second being the ability to have an almost infinte supply of data. Finally, this is one step closer to having an AI system that can build things beyond what it was taught. Beyond infact, what we can do as humans too.</p>

<p>The challenge? -&gt; When you have too many examples of different things, it is very easy to “forget” what you wanted. Or end up with a mash up of things. This is called mode collapse and many attempts to do it have been made.</p>

<h1 id="examples">Examples</h1>
<p>Before I go on to our simple GAN (on MNIST). Here are some results I got with the same GAN for different purposes.</p>

<ul>
  <li>The first was an attempt at creating Art. This was trained on a lot of art by various old artists. (zoom in a bit)</li>
</ul>

<p><img src="/assets/img/deconstrucImages/dcgan1.png" alt="drawing" /></p>

<ul>
  <li>This is trying to generate art from one of my closest friend’s work. Do check him out <a href="https://www.instagram.com/cinemcraft?igshid=fxzbanf9e8xq">here</a></li>
</ul>

<p><img src="/assets/img/deconstrucImages/dcgan2.png" alt="drawing" width="400" /></p>

<ul>
  <li>
    <p>This is trying to generate faces.</p>
  </li>
  <li>
    <p><img src="/assets/img/deconstrucImages/face.png" alt="drawing" width="300" /></p>
  </li>
  <li>
    <p>This is what we want to generate today (I know.. what even right?). Okay so I did cheat a bit, this animation was generated in Python a long time back when I first did DCGans there. But I get a bit of a waiver for this cool animation right??</p>
  </li>
</ul>

<p><img src="/assets/img/deconstrucImages/dcganmnist.gif" alt="drawing" /></p>

<h1 id="code">Code</h1>

<p>So let us get to making it? Hey! You did not explain how it works. 
Well I am a boring person by nature. xD. I will explain by code. 
But I want theory!!! Go check out the <a href="https://arxiv.org/pdf/1511.06434.pdf%C3">Paper</a>.</p>

<h2 id="imports">Imports</h2>

<p>Let us first import whatever we need. We have covered all of these before so I will skip the explanations.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">Base</span><span class="o">.</span><span class="n">Iterators</span><span class="o">:</span> <span class="n">partition</span>
<span class="k">using</span> <span class="n">Flux</span>
<span class="k">using</span> <span class="n">Flux</span><span class="o">.</span><span class="n">Optimise</span><span class="o">:</span> <span class="n">update!</span>
<span class="k">using</span> <span class="n">Flux</span><span class="o">:</span> <span class="n">logitbinarycrossentropy</span>
<span class="k">using</span> <span class="n">Images</span>
<span class="k">using</span> <span class="n">MLDatasets</span>
<span class="k">using</span> <span class="n">Statistics</span>
<span class="k">using</span> <span class="n">Printf</span>
<span class="k">using</span> <span class="n">Random</span>
<span class="k">using</span> <span class="n">ImageView</span>
</code></pre></div></div>

<p>So our aim is to take a random noise the size we need and generate a sensible image out of it. Everything that is possible in that is called it’s latent space.</p>

<h2 id="constants">Constants</h2>

<p>We also need to define some constants. Batch size, the dimension of the space we are trying to recreate, Sizes we want. And different (or same) learning rates for the two parts of our network.</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">300</span>

<span class="n">verbose_freq</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">output_x</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">output_y</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">lr_dscr</span> <span class="o">=</span> <span class="mf">0.0002</span>
<span class="n">lr_gen</span> <span class="o">=</span> <span class="mf">0.0002</span>
</code></pre></div></div>

<p>Now we need a way to plot our function from</p>

<p>So our network is made up of two parts. The first is a vanilla classifier with a bit of drama added on. It tells us how good our created image is. We call this the “Discriminator” because.. because well that’s what it does.</p>

<h2 id="discriminator">Discriminator</h2>

<p>If you notice, this is just a simple classifier. Nothing new here. Maybe except leaky relu. Why not relu? Because trial and error proved otherwise.(And a blog I linked towards the end of this article)</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> Discriminator</span><span class="x">()</span>
    <span class="k">return</span> <span class="n">Chain</span><span class="x">(</span>
            <span class="n">Conv</span><span class="x">((</span><span class="mi">4</span><span class="x">,</span> <span class="mi">4</span><span class="x">),</span> <span class="mi">1</span> <span class="o">=&gt;</span> <span class="mi">64</span><span class="x">;</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span><span class="x">,</span> <span class="n">pad</span> <span class="o">=</span> <span class="mi">1</span><span class="x">),</span>
            <span class="n">x</span><span class="o">-&gt;</span><span class="n">leakyrelu</span><span class="o">.</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="mf">0.2f0</span><span class="x">),</span>
            <span class="n">Dropout</span><span class="x">(</span><span class="mf">0.25</span><span class="x">),</span>
            <span class="n">Conv</span><span class="x">((</span><span class="mi">4</span><span class="x">,</span> <span class="mi">4</span><span class="x">),</span> <span class="mi">64</span> <span class="o">=&gt;</span> <span class="mi">128</span><span class="x">;</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span><span class="x">,</span> <span class="n">pad</span> <span class="o">=</span> <span class="mi">1</span><span class="x">),</span>
            <span class="n">x</span><span class="o">-&gt;</span><span class="n">leakyrelu</span><span class="o">.</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="mf">0.2f0</span><span class="x">),</span>
            <span class="n">Dropout</span><span class="x">(</span><span class="mf">0.25</span><span class="x">),</span> 
            <span class="n">x</span><span class="o">-&gt;</span><span class="n">reshape</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">128</span><span class="x">,</span> <span class="o">:</span><span class="x">),</span>
            <span class="n">Dense</span><span class="x">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">128</span><span class="x">,</span> <span class="mi">1</span><span class="x">))</span>	
<span class="k">end</span>
</code></pre></div></div>

<h2 id="generator">Generator</h2>

<p>Now for the main part. The main dude here. This would be a little weird to look at. So let us look at it first.</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> Generator</span><span class="x">()</span>
    <span class="k">return</span> <span class="n">Chain</span><span class="x">(</span>
            <span class="n">Dense</span><span class="x">(</span><span class="n">latent_dim</span><span class="x">,</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">256</span><span class="x">),</span>
            <span class="n">BatchNorm</span><span class="x">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">256</span><span class="x">,</span> <span class="n">relu</span><span class="x">),</span>
            <span class="n">x</span><span class="o">-&gt;</span><span class="n">reshape</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="mi">7</span><span class="x">,</span> <span class="mi">7</span><span class="x">,</span> <span class="mi">256</span><span class="x">,</span> <span class="o">:</span><span class="x">),</span>
            <span class="n">ConvTranspose</span><span class="x">((</span><span class="mi">5</span><span class="x">,</span> <span class="mi">5</span><span class="x">),</span> <span class="mi">256</span> <span class="o">=&gt;</span> <span class="mi">128</span><span class="x">;</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span><span class="x">,</span> <span class="n">pad</span> <span class="o">=</span> <span class="mi">2</span><span class="x">),</span>
            <span class="n">BatchNorm</span><span class="x">(</span><span class="mi">128</span><span class="x">,</span> <span class="n">relu</span><span class="x">),</span>
            <span class="n">ConvTranspose</span><span class="x">((</span><span class="mi">4</span><span class="x">,</span> <span class="mi">4</span><span class="x">),</span> <span class="mi">128</span> <span class="o">=&gt;</span> <span class="mi">64</span><span class="x">;</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span><span class="x">,</span> <span class="n">pad</span> <span class="o">=</span> <span class="mi">1</span><span class="x">),</span>
            <span class="n">BatchNorm</span><span class="x">(</span><span class="mi">64</span><span class="x">,</span> <span class="n">relu</span><span class="x">),</span>
            <span class="n">ConvTranspose</span><span class="x">((</span><span class="mi">4</span><span class="x">,</span> <span class="mi">4</span><span class="x">),</span> <span class="mi">64</span> <span class="o">=&gt;</span> <span class="mi">1</span><span class="x">,</span> <span class="n">tanh</span><span class="x">;</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span><span class="x">,</span> <span class="n">pad</span> <span class="o">=</span> <span class="mi">1</span><span class="x">),</span>
            <span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="conv-transpose">Conv Transpose</h2>

<p>Huhhhh. Whaaat????</p>

<p>Okay so first. What is conv transpose? I didn’t know it myself so I looked it up. <a href="https://towardsdatascience.com/transposed-convolution-demystified-84ca81b4baba#:~:text=Transposed convolution is also known,upsample the input feature map.">Great blog on it</a></p>

<p>Simply put, we take a smol image and try to reconstruct it to a bigger one. Why? Consider it to be an “up” convolution instead of a “down” convolution where the size reduces after the operation.</p>

<p>Okay but how? Consider our task of taking a matrix and a kernel. We pass the image through im2col to get our things together. After that we can do a matrix multiply if needed.</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="x">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="x">;</span> <span class="mi">6</span> <span class="mi">5</span> <span class="mi">3</span><span class="x">;</span> <span class="mi">1</span> <span class="mi">4</span> <span class="mi">1</span><span class="x">]</span>
<span class="n">col_data</span> <span class="o">=</span> <span class="n">im2col</span><span class="x">(</span><span class="n">tmp_cm</span><span class="x">,</span> <span class="x">(</span><span class="mi">3</span><span class="x">,</span> <span class="mi">3</span><span class="x">))</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="x">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">0</span> <span class="mi">2</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="x">;</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">0</span> <span class="mi">2</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="x">;</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">0</span> <span class="mi">2</span> <span class="mi">1</span> <span class="mi">0</span><span class="x">;</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">0</span> <span class="mi">2</span> <span class="mi">1</span><span class="x">]</span>
<span class="n">new_data</span> <span class="o">=</span> <span class="n">col2im</span><span class="x">(</span><span class="n">kernel</span><span class="o">*</span><span class="n">col_data</span><span class="x">,</span> <span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">2</span><span class="x">))</span>
</code></pre></div></div>

<p>Now what if we take the output of this and want to get the original back? To do that we basically pad the image. And then take the transpose of the kernel. And boom. 
This is something like a de - convolution. Except that is a misnomer.</p>

<p>Now armed with that knowlege, I would advice you to go back and look at our Generator function again.</p>

<p>Oh and before I forget. Notice the last Conv transpose’s activation function? Yes. It’s tanh. :) It seems to do better than relu for this layer due to some weight changes.</p>

<h2 id="loss-functions">Loss functions.</h2>

<p>Discriminator -&gt; We have a loss function which takes the loss for real and fake images and sums them up.</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> discriminator_loss</span><span class="x">(</span><span class="n">real_output</span><span class="x">,</span> <span class="n">fake_output</span><span class="x">)</span>
    <span class="n">real_loss</span> <span class="o">=</span> <span class="n">mean</span><span class="x">(</span><span class="n">logitbinarycrossentropy</span><span class="o">.</span><span class="x">(</span><span class="n">real_output</span><span class="x">,</span> <span class="mf">1f0</span><span class="x">))</span>
    <span class="n">fake_loss</span> <span class="o">=</span> <span class="n">mean</span><span class="x">(</span><span class="n">logitbinarycrossentropy</span><span class="o">.</span><span class="x">(</span><span class="n">fake_output</span><span class="x">,</span> <span class="mf">0f0</span><span class="x">))</span>
    <span class="k">return</span> <span class="n">real_loss</span> <span class="o">+</span> <span class="n">fake_loss</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Generator -&gt; Simple loss function as above</p>
<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generator_loss</span><span class="x">(</span><span class="n">fake_output</span><span class="x">)</span> <span class="o">=</span> <span class="n">mean</span><span class="x">(</span><span class="n">logitbinarycrossentropy</span><span class="o">.</span><span class="x">(</span><span class="n">fake_output</span><span class="x">,</span> <span class="mf">1f0</span><span class="x">))</span>
</code></pre></div></div>

<p>Now how about training?</p>

<h2 id="training">Training</h2>

<p>Discriminator -&gt; We first generate random noise. That will be our fake input. Then we can do a forward and backward pass on it.</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> train_discriminator!</span><span class="x">(</span><span class="n">gen</span><span class="x">,</span> <span class="n">dscr</span><span class="x">,</span> <span class="n">x</span><span class="x">,</span> <span class="n">opt_dscr</span><span class="x">)</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">randn!</span><span class="x">(</span><span class="n">similar</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="x">(</span><span class="n">latent_dim</span><span class="x">,</span> <span class="n">batch_size</span><span class="x">)))</span> 
    <span class="n">fake_input</span> <span class="o">=</span> <span class="n">gen</span><span class="x">(</span><span class="n">noise</span><span class="x">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">params</span><span class="x">(</span><span class="n">dscr</span><span class="x">)</span>
    <span class="c"># Taking gradient</span>
    <span class="n">loss</span><span class="x">,</span> <span class="n">back</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">pullback</span><span class="x">(</span><span class="n">ps</span><span class="x">)</span> <span class="k">do</span>
        <span class="n">discriminator_loss</span><span class="x">(</span><span class="n">dscr</span><span class="x">(</span><span class="n">x</span><span class="x">),</span> <span class="n">dscr</span><span class="x">(</span><span class="n">fake_input</span><span class="x">))</span>
    <span class="k">end</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">back</span><span class="x">(</span><span class="mf">1f0</span><span class="x">)</span>
    <span class="n">update!</span><span class="x">(</span><span class="n">opt_dscr</span><span class="x">,</span> <span class="n">ps</span><span class="x">,</span> <span class="n">grad</span><span class="x">)</span>
    <span class="k">return</span> <span class="n">loss</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Generator -&gt; For this we do almost the same exluding the loss function.</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> train_generator!</span><span class="x">(</span><span class="n">gen</span><span class="x">,</span> <span class="n">dscr</span><span class="x">,</span> <span class="n">x</span><span class="x">,</span> <span class="n">opt_gen</span><span class="x">)</span> 
    <span class="n">noise</span> <span class="o">=</span> <span class="n">randn!</span><span class="x">(</span><span class="n">similar</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="x">(</span><span class="n">latent_dim</span><span class="x">,</span> <span class="n">batch_size</span><span class="x">)))</span> 
    <span class="n">ps</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">params</span><span class="x">(</span><span class="n">gen</span><span class="x">)</span>
    <span class="c"># Taking gradient</span>
    <span class="n">loss</span><span class="x">,</span> <span class="n">back</span> <span class="o">=</span> <span class="n">Flux</span><span class="o">.</span><span class="n">pullback</span><span class="x">(</span><span class="n">ps</span><span class="x">)</span> <span class="k">do</span>
        <span class="n">generator_loss</span><span class="x">(</span><span class="n">dscr</span><span class="x">(</span><span class="n">gen</span><span class="x">(</span><span class="n">noise</span><span class="x">)))</span>
    <span class="k">end</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">back</span><span class="x">(</span><span class="mf">1f0</span><span class="x">)</span>
    <span class="n">update!</span><span class="x">(</span><span class="n">opt_gen</span><span class="x">,</span> <span class="n">ps</span><span class="x">,</span> <span class="n">grad</span><span class="x">)</span>
    <span class="k">return</span> <span class="n">loss</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="data">Data</h2>

<p>Then we can load the data.</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">images</span><span class="x">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">MLDatasets</span><span class="o">.</span><span class="n">MNIST</span><span class="o">.</span><span class="n">traindata</span><span class="x">(</span><span class="kt">Float32</span><span class="x">)</span>
<span class="c"># Normalize to [-1, 1]</span>
<span class="n">image_tensor</span> <span class="o">=</span> <span class="n">reshape</span><span class="x">(</span><span class="nd">@.</span><span class="x">(</span><span class="mf">2f0</span> <span class="o">*</span> <span class="n">images</span> <span class="o">-</span> <span class="mf">1f0</span><span class="x">),</span> <span class="mi">28</span><span class="x">,</span> <span class="mi">28</span><span class="x">,</span> <span class="mi">1</span><span class="x">,</span> <span class="o">:</span><span class="x">)</span>
<span class="c"># Partition into batches</span>
<span class="n">data</span> <span class="o">=</span> <span class="x">[</span><span class="n">image_tensor</span><span class="x">[</span><span class="o">:</span><span class="x">,</span> <span class="o">:</span><span class="x">,</span> <span class="o">:</span><span class="x">,</span> <span class="n">r</span><span class="x">]</span> <span class="o">|&gt;</span> <span class="n">gpu</span> <span class="k">for</span> <span class="n">r</span> <span class="k">in</span> <span class="n">partition</span><span class="x">(</span><span class="mi">1</span><span class="o">:</span><span class="mi">60000</span><span class="x">,</span> <span class="n">batch_size</span><span class="x">)]</span>

<span class="n">fixed_noise</span> <span class="o">=</span> <span class="x">[</span><span class="n">randn</span><span class="x">(</span><span class="n">latent_dim</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span> <span class="o">|&gt;</span> <span class="n">gpu</span> <span class="k">for</span> <span class="n">_</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span><span class="n">output_x</span><span class="o">*</span><span class="n">output_y</span><span class="x">]</span>
</code></pre></div></div>

<h2 id="loop">Loop</h2>

<p>Let us train our network.</p>
<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">ep</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">epochs</span>
    <span class="kd">global</span> <span class="n">train_steps</span>
    <span class="nd">@info</span> <span class="s">"Epoch </span><span class="si">$</span><span class="s">ep"</span>
    <span class="k">for</span> <span class="n">x</span> <span class="k">in</span> <span class="n">data</span>
        <span class="c"># Update discriminator and generator</span>
        <span class="n">loss_dscr</span> <span class="o">=</span> <span class="n">train_discriminator!</span><span class="x">(</span><span class="n">gen</span><span class="x">,</span> <span class="n">dscr</span><span class="x">,</span> <span class="n">x</span><span class="x">,</span> <span class="n">opt_dscr</span><span class="x">)</span> 
        <span class="n">loss_gen</span> <span class="o">=</span> <span class="n">train_generator!</span><span class="x">(</span><span class="n">gen</span><span class="x">,</span> <span class="n">dscr</span><span class="x">,</span> <span class="n">x</span><span class="x">,</span> <span class="n">opt_gen</span><span class="x">)</span>

        <span class="k">if</span> <span class="n">train_steps</span> <span class="o">%</span> <span class="n">verbose_freq</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="nd">@info</span><span class="x">(</span><span class="s">"Train step </span><span class="si">$(train_steps)</span><span class="s">, Discriminator loss = </span><span class="si">$(loss_dscr)</span><span class="s">, Generator loss = </span><span class="si">$(loss_gen)</span><span class="s">"</span><span class="x">)</span>
            <span class="c"># Save generated fake image</span>
            <span class="c"># output_image = create_output_image(gen, fixed_noise)</span>
            <span class="c"># save(@sprintf("output/dcgan_steps_%06d.png", train_steps), output_image)</span>
        <span class="k">end</span>
        <span class="n">train_steps</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="output-image">Output image</h2>

<p>Now that we have everything we need, we need to grab our image from this hot mess. Do do that, we first set the network as not training. Then take the current fixed noise, pass it through the generator and pop them into the CPU. After that we set the mode to eval (aka generation) and convert this into an image array we can use.</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> create_output_image</span><span class="x">(</span><span class="n">gen</span><span class="x">,</span> <span class="n">fixed_noise</span><span class="x">)</span>
    <span class="nd">@eval</span> <span class="n">Flux</span><span class="o">.</span><span class="n">istraining</span><span class="x">()</span> <span class="o">=</span> <span class="nb">false</span>
    <span class="n">fake_images</span> <span class="o">=</span> <span class="nd">@.</span> <span class="n">cpu</span><span class="x">(</span><span class="n">gen</span><span class="x">(</span><span class="n">fixed_noise</span><span class="x">))</span>
    <span class="nd">@eval</span> <span class="n">Flux</span><span class="o">.</span><span class="n">istraining</span><span class="x">()</span> <span class="o">=</span> <span class="nb">true</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="n">permutedims</span><span class="x">(</span><span class="n">dropdims</span><span class="x">(</span><span class="n">reduce</span><span class="x">(</span><span class="n">vcat</span><span class="x">,</span> <span class="n">reduce</span><span class="o">.</span><span class="x">(</span><span class="n">hcat</span><span class="x">,</span> <span class="n">partition</span><span class="x">(</span><span class="n">fake_images</span><span class="x">,</span> <span class="n">output_y</span><span class="x">)));</span> <span class="n">dims</span><span class="o">=</span><span class="x">(</span><span class="mi">3</span><span class="x">,</span> <span class="mi">4</span><span class="x">)),</span> <span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">1</span><span class="x">))</span>
    <span class="n">image_array</span> <span class="o">=</span> <span class="nd">@.</span> <span class="n">Gray</span><span class="x">(</span><span class="n">image_array</span> <span class="o">+</span> <span class="mf">1f0</span><span class="x">)</span> <span class="o">/</span> <span class="mf">2f0</span>
    <span class="k">return</span> <span class="n">image_array</span>
<span class="k">end</span>

<span class="n">output_image</span> <span class="o">=</span> <span class="n">create_output_image</span><span class="x">(</span><span class="n">gen</span><span class="x">,</span> <span class="n">fixed_noise</span><span class="x">)</span>
<span class="n">imshow</span><span class="x">(</span><span class="n">output_image</span><span class="x">)</span>
</code></pre></div></div>

<p>Aand… we are done :)</p>

<h1 id="further-reading">Further reading</h1>

<p>I actually wrote a blog. And even gave a webinar on this topic. So if you want to check them out..</p>

<ul>
  <li><a href="https://medium.com/acmvit/the-infinite-art-machine-3a2decab85d9">Blog</a></li>
  <li><a href="https://www.youtube.com/watch?v=zLtKCBXhyAs&amp;list=PLpmmExpJxZVRFPAXCYF8SKKFeKq-Dw6d5&amp;index=7&amp;t=0s">Intersection of AI and Art</a></li>
  <li><a href="https://github.com/hindupuravinash/the-gan-zoo">A whole list of types of GANs</a></li>
  <li><a href="https://github.com/soumith/ganhacks">GAN Hax from the creator of Pytorch</a></li>
</ul>


<section>
Related posts:&emsp;

  <a href=/book/2021/03/09/AISuperpowersKaiFuLee.html> AI Superpowers Kai Fu Lee&emsp; </a>

  <a href=/book/2021/03/07/DigitalMinimalismCalNewport.html> Digital Minimalism Cal Newport&emsp; </a>

  <a href=/article/2021/03/05/tricksFromLectures.html> More Deep Learning, Less Crying - A guide&emsp; </a>

  <a href=/article/2020/10/09/SuperRes.html> Super resolution&emsp; </a>

  <a href=/article/2020/10/07/FederatedLearning.html> Federated Learning&emsp; </a>

  <a href=/article/2020/10/03/TakingBatchnormForGranted.html> Taking Batchnorm For Granted&emsp; </a>

  <a href=/article/2020/09/28/AdversarialAttack.html> A murder mystery and Adversarial attack&emsp; </a>

  <a href=/article/2020/09/26/An.html> Thank you and a rain check&emsp; </a>

  <a href=/article/2020/09/25/Pruning.html> Pruning&emsp; </a>

  <a href=/article/2020/09/04/Documentation.html> Documentation using Documenter.jl&emsp; </a>


</section>


    </div>
  </body>
</html>
