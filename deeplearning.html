<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href ="/assets/css/landing.css">
  </head>
  <body>
    <div class="col-md-5">
      <header>
        <h2><a id = "imp" href="/">Home page</a></h2>
       
        <p>Deconstructing Deep Learning +  δeviations</p>
        
        <p>
          Drop me an <a href = "mailto: msubhaditya@gmail.com">email</a>
          | RSS feed link : <a href ="https://subhadityamukherjee.github.io/feed.xml">Click</a><br>
          Format : 
          Date | Title<br>
          &emsp;&emsp;TL; DR<br>
          <h4>Total number of posts : 88</h4>
         Go To : <a style="font-size:20px;color:white;" href="#PAPER">PAPERS</a> o
        <a style="font-size:20px;color:white;" href="#ARTICLE">ARTICLES</a> o
        <a style="font-size:20px;color:white;" href="#BOOK">BOOKS</a> o
        <a style="font-size:20px;color:white;" href="#SPACE">SPACE</a>
         
          <div id="search-container">
            Search for something in the blog <input type="text" id="search-input" placeholder="search...">
          </div><br>
          <ul id="results-container"></ul>
        </p>
        
        
        <p class="view">
        <a href="https://www.github.com/SubhadityaMukherjee">View My GitHub Profile </a>
        </p>
      </header>
      
      <hr>
      <script src="/assets/js/search-script.js" type="text/javascript"></script>
      
      <script>
        SimpleJekyllSearch({
          searchInput: document.getElementById('search-input'),
          resultsContainer: document.getElementById('results-container'),
          json: '/assets/search.json'
        })
        </script>
    </div>
<section>
        <div class=col-md-5>
  
<p><a href="#top">Go Up</a></p>
<h2 id="ARTICLE"> ARTICLE </h2>

<ul>

  
  <li>
  
	    <h3><a href="/article/2021/03/05/tricksFromLectures.html"> More deep learning, less crying - a guide : Mar 2021 </a></h3>
	<p>This is a guide to make deep learning less messy and hopefully give you a way to use less tissues next time you code.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/10/09/SuperRes.html"> Super resolution : Oct 2020 </a></h3>
	<p>Today we will look at Super Resolution in Python.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/10/07/FederatedLearning.html"> Federated learning : Oct 2020 </a></h3>
	<p>Today we will talk about Federated Learning</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/10/03/TakingBatchnormForGranted.html"> Taking batchnorm for granted : Oct 2020 </a></h3>
	<p>Here we will see what happens when we “dont” take Batchnorm for granted.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/09/28/AdversarialAttack.html"> A murder mystery and adversarial attack : Sep 2020 </a></h3>
	<p>How smart are neural networks? And can we break them and fool them into doing dumb things?</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/09/26/An.html"> Thank you and a rain check : Sep 2020 </a></h3>
	<p>Hello dear reader, I share a quick rain check and announce my medium page :)</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/09/25/Pruning.html"> Pruning : Sep 2020 </a></h3>
	<p>Today we will look at pruning and the different approaches followed.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/09/04/Documentation.html"> Documentation using documenter.jl : Sep 2020 </a></h3>
	<p>Here we will talk about how to document your code using Documenter.jl and a few tips along the way.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/09/02/DatasetBindings.html"> Dataset bindings : Sep 2020 </a></h3>
	<p>Tiny post on datasets and a unified downloader for standard ones.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/08/25/DCGAN.html"> Dcgan : Aug 2020 </a></h3>
	<p>Here we will talk about Generative Networks and implement a simple version of DC GAN.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/08/12/Differentiable-Programming.html"> Differentiable programming : Aug 2020 </a></h3>
	<p>Deep Learning is dead. Hello Differentiable Programming. (Uh come on man)</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/08/11/Compositional-Pattern-Producing-Networks.html"> Compositional pattern producing networks : Aug 2020 </a></h3>
	<p>Today we will talk about Compositional Pattern Producing Networks.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/08/11/VGG.html"> Vgg : Aug 2020 </a></h3>
	<p>Here we will talk about VGG networks and how to implement VGG16 and VGG19.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/28/Optimizers.html"> Optimizers : Jul 2020 </a></h3>
	<p>Finally let us look at optimizers. Once that is done, we will be able to use Flux ML for a lot of things directly.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/25/VAE.html"> Vae : Jul 2020 </a></h3>
	<p>A simple Variational Auto Encoder using just what we made so far!!</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/25/convFlux.html"> Simple conv with flux : Jul 2020 </a></h3>
	<p>Using the library functions which we defined till now to run a simple Neural Network.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/24/rnnFromScratch.html"> Rnn from scratch : Jul 2020 </a></h3>
	<p>(WIP Skip for now) NLP time!! Here we will look at an RNN from scratch.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/24/backprop.html"> Backprop : Jul 2020 </a></h3>
	<p>Looking at backpropagation from scratch because somehow I have not done that yet.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/21/Low-Poly.html"> Low poly : Jul 2020 </a></h3>
	<p>Convert a video to low poly :) (See images below if you dont know what that is)</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/18/Universal-Approximation-theorem.html"> Universal approximation theorem : Jul 2020 </a></h3>
	<p>What makes Neural Networks tick mathematically.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/16/preprocessing.html"> Image preprocessing : Jul 2020 </a></h3>
	<p>We look at some image processing techniques and try to implement them from scratch.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/12/fastai-Book.html"> Fastai book : Jul 2020 </a></h3>
	<p>What I found interesting from the book “Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD”
by Jeremy Howard  (Author), Sylvain Gugger (Author)</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/11/pooling.html"> Pooling layers : Jul 2020 </a></h3>
	<p>Here we will look at the pooling operation and its types.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/10/evenFasterConv.html"> My life is a lie + even faster conv : Jul 2020 </a></h3>
	<p>Why CNNs are Correlation Neural Networks and an even faster Convolution operation.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/09/mandelbrot.html"> Mandelbrot set : Jul 2020 </a></h3>
	<p>Have you heard of fractal patterns? Here we will try to make some :) (look at the pictures at the end)</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/07/Action-Recognition-part-2.html"> Action recognition part 2 : Jul 2020 </a></h3>
	<p>Continuing the action recognition project.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/06/Video-Classification.html"> Action recognition part 1 : Jul 2020 </a></h3>
	<p>I try to reimplement Video recognition from <a href="https://github.com/jfzhang95/pytorch-video-recognition">Link</a> and explain the code as I go along.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/06/Endangered-Species.html"> Endangered species : Jul 2020 </a></h3>
	<p>Here we will talk about spreading awareness about endangered species through AI powered art.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/04/padding.html"> Padding : Jul 2020 </a></h3>
	<p>To implement a faster conv we need padding, so here we will try to explore what that means and try to implement it.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/03/fasterConv.html"> Faster and more general conv : Jul 2020 </a></h3>
	<p>Here we will look at the various ways of implementing convolutions and benchmark them.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/02/kernels.html"> Image kernels : Jul 2020 </a></h3>
	<p>Image kernels are fun as filters, so let us just look at a few of them and maybe try something else?</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/02/convolution.html"> Basic convolution : Jul 2020 </a></h3>
	<p>Here we will talk about convolution and how to implement it from scratch.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/07/01/time.html"> Imposter syndrome in the research community : Jul 2020 </a></h3>
	<p>How to deal with imposter syndrome and what causes it.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/30/latex-from-code.html"> Latex from code : Jun 2020 </a></h3>
	<p>I want to talk about how to get these beautiful looking latex equations without any effort at all.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/29/loss-functions.html"> Loss functions : Jun 2020 </a></h3>
	<p>In this post we shall explore as many loss functions as I can find.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/27/Implementing-Papers.html"> Implementing papers : Jun 2020 </a></h3>
	<p>Notes for papers I read?</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/27/100PageMlbook.html"> 100pagemlblook : Jun 2020 </a></h3>
	<p>Notes from 100 Page ML Book</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/24/SGD.html"> Sgd : Jun 2020 </a></h3>
	<p>In this post we will try to implement SGD and read a bit about what it is.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/23/batching.html"> Batching : Jun 2020 </a></h3>
	<p>Implementing batching for large data.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/21/initialization.html"> Initialization : Jun 2020 </a></h3>
	<p>We explore the different initialization techniques that we have and look at papers to see which does better.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/20/layers.html"> Linear model : Jun 2020 </a></h3>
	<p>Let us start the fun with a simple model which will be extended to fit complex needs.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/19/activationFunctions.html"> Activation functions : Jun 2020 </a></h3>
	<p>Implementing activation functions.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/19/Vision.html"> Vision : Jun 2020 </a></h3>
	<p>A roadmap of modules I want to implement. Mostly as a todo list and a help if anyone decides they want to pitch in. (LOL)</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/19/notebook2script.html"> Notebook2script : Jun 2020 </a></h3>
	<p>I want to convert my work as a script. Selectively.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/19/trainTest.html"> Oversample and split : Jun 2020 </a></h3>
	<p>Defining a function to split the dataset into train/test bits and oversample it as well.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/19/dataloader.html"> Dataloader : Jun 2020 </a></h3>
	<p>The first thing we need is to be able to read data. To begin with, I am starting with the problem of image classification.</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/19/Initial-Steps.html"> Initial steps : Jun 2020 </a></h3>
	<p>What I started with and how I set up this blog</p>


	
  </li>
  

  
  <li>
  
	    <h3><a href="/article/2020/06/19/Defining-the-problem.html"> Defining the project and outlining what is to come in the future : Jun 2020 </a></h3>
	<p>An introduction to what I want to do and why.</p>


	
  </li>
  

</ul>

<p><a href="#top">Go Up</a></p>
<h2 id="PAPER"> PAPER </h2>

<ul>

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/swish.html"> Swish</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/shufflenet.html"> Shufflenet</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/selu.html"> Selu</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/randomErasingAugmentation.html"> Random erasing data augmentation</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/bagOfTricks.html"> Bag of tricks</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/WGAN.html"> Wgan</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/VGGNet.html"> Vgg net</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/VAE.html"> Vae (auto-encoding variational bayes)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/Unet.html"> Unets</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/Thinking-machines-Turing.html"> Thinking machines - turing (just notes)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/SuperResolution.html"> Super resolution using sub pixel convolutions</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/SqueezeNet.html"> Squeeze net</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/Spatial-Transformer-Network.html"> Spatial transformer networks</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/SRCNN.html"> Srcnn</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/Rethinking-Generalization.html"> Understanding deep learning requires rethinking generalization (just notes)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/ResNet.html"> Google net</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/Pruning.html"> What is the state of pruning</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/Perceptual-Loss.html"> Perceptual loss</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/OneCycle.html"> One cycle paper</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/NVAE.html"> Nvae (wip)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/NN-hyper-parameters-disciplined-approach.html"> A disciplined approach to neural network hyper-parameters</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/MobileNet.html"> Mobile net</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/LightSeg.html"> Lightseg (only notes for now)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/LSTM.html"> Lstm</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/HRNet.html"> Hrnet (wip)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/GoogLeNet.html"> Google net</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/Focal-Loss.html"> Focal loss</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/FederatedLearningGboard.html"> Google keyboard federated learning(notes only. refer to [35] for code)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/FederatedLearning.html"> Federated learning (original paper)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/Dropout.html"> Dropout (just notes)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/DeepLab-(Semantic-seg).html"> Semantic segmentation deeplab</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/DeepDream.html"> Inceptionism (google deep dream)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/DRlNeuro.html"> Drl and neuroscience (just notes</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/DCGan.html"> Dc gan</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/ComputationalLimits.html"> Computational limits (just notes)</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/Class-Imbalance.html"> Class imbalance problem</a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/paper/2020/06/19/AlexNet.html"> Alex net</a></h3>
	
  </li>
  

</ul>

<p><a href="#top">Go Up</a></p>
<h2 id="SPACE"> SPACE </h2>

<ul>

  
  <li>
  
	    <h3><a href="/space/2020/07/06/adopt.html"> Adopt dont shop : Jul 2020 </a></h3>
	<p>I want to talk about adopting animals.</p>


	
  </li>
  

</ul>

<p><a href="#top">Go Up</a></p>
<h2 id="BOOK"> BOOK </h2>

<ul>

  
  <li>
  
	    <h3><a href="/book/2021/03/09/AISuperpowersKaiFuLee.html"> Ai superpowers kai fu lee : Mar 2021 </a></h3>
	
  </li>
  

  
  <li>
  
	    <h3><a href="/book/2021/03/07/DigitalMinimalismCalNewport.html"> Digital minimalism cal newport : Mar 2021 </a></h3>
	
  </li>
  

</ul>


        </div>
  </body>
</html>
